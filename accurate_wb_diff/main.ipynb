{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import base64\n",
    "from bs4 import BeautifulSoup\n",
    "import ia_wayback_dataset\n",
    "import itertools\n",
    "import os\n",
    "from simhash import Simhash\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pure_text_from_html(html):\n",
    "    soup = BeautifulSoup(html, features='lxml')\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()\n",
    "    return soup.get_text(' ').lower()\n",
    "    # this frees up memory https://stackoverflow.com/questions/11284643/python-high-memory-usage-with-beautifulsoup\n",
    "    soup.decompose()\n",
    "    return text\n",
    "\n",
    "simhash_size = 128\n",
    "TRANSLATOR = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "def simhash_by_wayback_default(text):\n",
    "    text = text.translate(TRANSLATOR)\n",
    "    back_of_words = collections.Counter(text.split())\n",
    "    return Simhash(back_of_words, simhash_size)\n",
    "\n",
    "def hamming_distance(a, b):\n",
    "    return bin(a^b).count('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas to try\n",
    "- filter stop words\n",
    "- simhash with bigrams, simhash with shingles, minhash, edit distance, jaccard similarity and etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory /var/datasets/ia/wbm/urls/a5d099af8ea22a17edc3bc46b6535aeb already exist\n",
      "created file /var/datasets/ia/wbm/captures/WUAFJGAQZ4X5TBSPQWIE5TP7L6TZIX6I\n",
      "20180214132613  -  hamming distance 0\n",
      "20180322205857  -  hamming distance 1\n",
      "20180330062934  -  hamming distance 2\n",
      "20180404202601  -  hamming distance 0\n",
      "20180406020136  -  hamming distance 0\n",
      "20180414222149  -  hamming distance 0\n",
      "20180420033338  -  hamming distance 0\n",
      "20180427021344  -  hamming distance 0\n",
      "20180504090033  -  hamming distance 0\n",
      "20180510211558  -  hamming distance 0\n",
      "20180518141208  -  hamming distance 0\n",
      "20180526062520  -  hamming distance 0\n",
      "20180602081826  -  hamming distance 0\n",
      "20180621233326  -  hamming distance 1\n",
      "20180628230017  -  hamming distance 0\n",
      "20180705212030  -  hamming distance 0\n",
      "20180726161616  -  hamming distance 0\n",
      "20180802205833  -  hamming distance 1\n",
      "20180809213815  -  hamming distance 0\n",
      "20180817024652  -  hamming distance 0\n",
      "20180824005543  -  hamming distance 0\n",
      "20180830231238  -  hamming distance 0\n",
      "20180907011455  -  hamming distance 0\n",
      "20180913203256  -  hamming distance 0\n",
      "20180920183721  -  hamming distance 0\n",
      "20180928160919  -  hamming distance 0\n",
      "20181005201045  -  hamming distance 0\n",
      "20181011182849  -  hamming distance 0\n",
      "20181018192437  -  hamming distance 0\n",
      "20181025183342  -  hamming distance 1\n",
      "20181101211903  -  hamming distance 0\n",
      "20181109124020  -  hamming distance 0\n",
      "20181117152209  -  hamming distance 2\n",
      "20181122141449  -  hamming distance 0\n",
      "20181125154305  -  hamming distance 4\n",
      "20181129195626  -  hamming distance 4\n",
      "20181206201347  -  hamming distance 0\n",
      "20181220120043  -  hamming distance 0\n",
      "20181229010428  -  hamming distance 0\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "captures = ia_wayback_dataset.load_data(\n",
    "    url='https://reactjs.org/blog/all.html', year=2018, path='/var/datasets/ia')\n",
    "\n",
    "def convert_text_to_simhash(capture_data):\n",
    "    text = extract_pure_text_from_html(capture_data)\n",
    "    return simhash_by_wayback_default(text)\n",
    "\n",
    "captures_with_simhash = list(map(lambda c: (c[0], convert_text_to_simhash(c[2]).value), captures))\n",
    "for (_,simhash_of_capture_previous), (timestamp, simhash_of_capture) in zip(captures_with_simhash, captures_with_simhash[1:]):\n",
    "    print(timestamp, ' -  hamming distance', hamming_distance(simhash_of_capture_previous, simhash_of_capture))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fetch IA wayback captures for specific url and year to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets_path = os.environ.get('DATA_SET', '/var/datasets/ia')\n",
    "set_dataset_path(datasets_path)\n",
    "\n",
    "store_captures_to_dataset('https://reactjs.org/blog/all.html', 2019)\n",
    "store_captures_to_dataset('https://reactjs.org/blog/all.html', 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%ls -la /var/datasets/ia/wbm/captures/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
