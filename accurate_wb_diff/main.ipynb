{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_Environ' object has no attribute 'PYTHONPATH'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f4ae1ceb2946>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPYTHONPATH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: '_Environ' object has no attribute 'PYTHONPATH'"
     ]
    }
   ],
   "source": [
    "os.environ.PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempted relative import beyond top-level package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1f48417e4926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mdataset_downloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstore_captures_to_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: attempted relative import beyond top-level package"
     ]
    }
   ],
   "source": [
    "from ...dataset_downloader import store_captures_to_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = os.environ.get('DATA_SET', '/var/datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : may be good idea to use it because we would have similar to url filename\n",
    "# from slugify import slugify \n",
    "import json\n",
    "import hashlib\n",
    "import urllib3\n",
    "\n",
    "import os\n",
    "import errno\n",
    "\n",
    "def ensure_dir(directory):\n",
    "    try:\n",
    "        os.makedirs(directory)\n",
    "        print(f'create directory {directory}')\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise e\n",
    "        print(f'directory {directory} already exist')\n",
    "        \n",
    "headers = None\n",
    "http = urllib3.HTTPConnectionPool('web.archive.org', maxsize=50,\n",
    "                                   retries=urllib3.Retry(3, redirect=2),\n",
    "                                   headers=headers)\n",
    "\n",
    "def get_captures_of_url_and_year(url, year):\n",
    "    # Collapse captures by timestamp to get 1 capture per hour.\n",
    "    # Its necessary to reduce the huge number of captures some websites\n",
    "    # (e.g. twitter.com has 167k captures for 2018. Get only 2xx captures.\n",
    "    cdx_url = f'/cdx/search/cdx?url={url}&from={year}&to={year}&' \\\n",
    "               'fl=timestamp,digest&collapse=timestamp:10&statuscode=200'\n",
    "    response = http.request('GET', cdx_url)\n",
    "    assert response.status == 200\n",
    "    assert response.data\n",
    "    captures_txt = response.data.decode('utf-8')\n",
    "    captures = [l.split(' ') for l in captures_txt.strip().split(\"\\n\")]\n",
    "    return captures\n",
    "\n",
    "def download_capture(url, timestamp):\n",
    "    resp = http.request('GET', f'/web/{timestamp}id_/{url}')\n",
    "    return resp.data.decode('utf-8', 'ignore')    \n",
    "\n",
    "stored = {}\n",
    "\n",
    "\n",
    "# TODO: can make it in parallel\n",
    "def for_each_capture(url, year):\n",
    "    captures = get_captures_of_url_and_year(url, year)\n",
    "    # TODO: can make it in parallel\n",
    "    for c in captures:\n",
    "        [timestamp, digest] = c\n",
    "        duplicated = False\n",
    "        if digest not in stored:\n",
    "            response_data = download_capture(url, timestamp)\n",
    "            # TODO: store to file\n",
    "            stored[digest] = response_data\n",
    "        else:\n",
    "            duplicated = True\n",
    "            response_data = stored[digest]\n",
    "            \n",
    "        yield (timestamp, digest, response_data, duplicated)\n",
    "\n",
    "def encode_url_to_path(url):\n",
    "    if isinstance(url, str):\n",
    "        url = url.encode('utf-8')\n",
    "    return hashlib.md5(url).hexdigest()\n",
    "\n",
    "def store_captures_to_dataset(url, year):\n",
    "    url_to_path = encode_url_to_path(url)\n",
    "    dataset_path = f'{datasets_path}/ia/wbm'\n",
    "    dataset_path_captures = f'{dataset_path}/captures'\n",
    "    dataset_path_urls = f'{dataset_path}/urls'\n",
    "\n",
    "    ensure_dir(dataset_path_captures)\n",
    "    captures = []\n",
    "    for timestamp, digest, data, duplicated in for_each_capture(url, year):\n",
    "        # TODO: store to file\n",
    "        print('get data of ', timestamp, 'digest', digest, 'size', len(data), 'duplicate', duplicated)\n",
    "\n",
    "        # store captures of year\n",
    "        file_name = f'{dataset_path_captures}/{digest}'\n",
    "        if not duplicated:\n",
    "            if not os.path.isfile(file_name):\n",
    "                with open(file_name, 'w+') as capture_data_file:\n",
    "                    capture_data_file.write(data)\n",
    "                print(f'created file {file_name}')\n",
    "            else:\n",
    "                print(f'already have {file_name}')\n",
    "        captures.append([timestamp, digest])\n",
    "\n",
    "    file_name = f'{dataset_path_urls}/{url_to_path}/{year}'\n",
    "    if not os.path.isfile(file_name):\n",
    "        ensure_dir(f'{dataset_path_urls}/{url_to_path}')\n",
    "        with open(file_name, 'w+') as url_captures_file:\n",
    "            url_captures_file.write(json.dumps(captures))\n",
    "        print(f'created file {file_name}')\n",
    "    else:\n",
    "        print(f'already have {file_name}')\n",
    "\n",
    "    print('we got all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory /var/datasets/ia/wbm/captures already exist\n",
      "get data of  20190103131300 digest L5BSSVD5RZJSH7ROECXBDWITK4UFWUXG size 85249 duplicate False\n",
      "already have /var/datasets/ia/wbm/captures/L5BSSVD5RZJSH7ROECXBDWITK4UFWUXG\n",
      "get data of  20190110122215 digest LK6UWHFG4DBLQCNF4MW3RS7ECJIJ6O5Q size 85249 duplicate False\n",
      "already have /var/datasets/ia/wbm/captures/LK6UWHFG4DBLQCNF4MW3RS7ECJIJ6O5Q\n",
      "get data of  20190117185403 digest ZA7BK666OTUPAXGSCOU3WT6CXXMCIUV4 size 85249 duplicate False\n",
      "already have /var/datasets/ia/wbm/captures/ZA7BK666OTUPAXGSCOU3WT6CXXMCIUV4\n",
      "get data of  20190125232432 digest DEF74AUAWCAIQBSM727UVAYKEDNWH4O5 size 85245 duplicate False\n",
      "already have /var/datasets/ia/wbm/captures/DEF74AUAWCAIQBSM727UVAYKEDNWH4O5\n",
      "get data of  20190207131826 digest UYEWLPMCLR6CGWMH5IIYW2BSEUD4FI6D size 85511 duplicate False\n",
      "already have /var/datasets/ia/wbm/captures/UYEWLPMCLR6CGWMH5IIYW2BSEUD4FI6D\n",
      "already have /var/datasets/ia/wbm/urls/a5d099af8ea22a17edc3bc46b6535aeb/2019\n",
      "we got all\n",
      "directory /var/datasets/ia/wbm/captures already exist\n",
      "get data of  20180202141408 digest 3I42H3S6NNFQ2MSVX7XZKYAYSCX5QBYJ size 105124 duplicate False\n",
      "already have /var/datasets/ia/wbm/captures/3I42H3S6NNFQ2MSVX7XZKYAYSCX5QBYJ\n",
      "get data of  20180214132613 digest LQVFP25IB2LSUFCFC4CDN5G3UQO4IRPM size 105124 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/LQVFP25IB2LSUFCFC4CDN5G3UQO4IRPM\n",
      "get data of  20180322205857 digest WSENYGTQRXJ5LNFGHSNQUWH4PB5GEIL2 size 105501 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/WSENYGTQRXJ5LNFGHSNQUWH4PB5GEIL2\n",
      "get data of  20180330062934 digest YPCA7YY2PVF6SWZJY5INY4RSHGXVUMW3 size 111935 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/YPCA7YY2PVF6SWZJY5INY4RSHGXVUMW3\n",
      "get data of  20180404202601 digest KZ46UQTOHTN2OD7O3RPTSXCSXLSOM4NV size 111935 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/KZ46UQTOHTN2OD7O3RPTSXCSXLSOM4NV\n",
      "get data of  20180406020136 digest 4Y3HB5PIWL4B7NJXQRSD4QXZT7QA56GQ size 111935 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/4Y3HB5PIWL4B7NJXQRSD4QXZT7QA56GQ\n",
      "get data of  20180414222149 digest GZAGLNDBVVZ2CJGP3JCL5TX6MIYEDM6L size 112831 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/GZAGLNDBVVZ2CJGP3JCL5TX6MIYEDM6L\n",
      "get data of  20180420033338 digest 6ZMC7XC62LV3A7NP3GLUJ3YW3VTNLZFE size 112903 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/6ZMC7XC62LV3A7NP3GLUJ3YW3VTNLZFE\n",
      "get data of  20180427021344 digest NYKLGBOVH3TGPUXSJ7CK22QPRSPL5TWD size 112903 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/NYKLGBOVH3TGPUXSJ7CK22QPRSPL5TWD\n",
      "get data of  20180504090033 digest 3VH4KC64AQSSUU64BSM6KNPYGPZEGL6Y size 112903 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/3VH4KC64AQSSUU64BSM6KNPYGPZEGL6Y\n",
      "get data of  20180510211558 digest DRT22WB2QX4NUOCJQMG7MW6472MGUK3T size 112903 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/DRT22WB2QX4NUOCJQMG7MW6472MGUK3T\n",
      "get data of  20180518141208 digest NTQ2WGTCLDJQWX3KCB7EHPYKYBE3VNPW size 112903 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/NTQ2WGTCLDJQWX3KCB7EHPYKYBE3VNPW\n",
      "get data of  20180526062520 digest JHWK6PF3JYBOIN7BLG4XVMIZB44ISFW2 size 113365 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/JHWK6PF3JYBOIN7BLG4XVMIZB44ISFW2\n",
      "get data of  20180602081826 digest 6G6ALNC7PFZARXDRZLSPRQPPRNDHCUXW size 113365 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/6G6ALNC7PFZARXDRZLSPRQPPRNDHCUXW\n",
      "get data of  20180621233326 digest KHZJLS2GAE4XDAXJ4TBHNBHQQ54DMNTA size 113782 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/KHZJLS2GAE4XDAXJ4TBHNBHQQ54DMNTA\n",
      "get data of  20180628230017 digest EX5JXMPE6NWTW3NGGU2JBSBXNHFHDGWS size 114314 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/EX5JXMPE6NWTW3NGGU2JBSBXNHFHDGWS\n",
      "get data of  20180705212030 digest UOUASLVAWT2CERC53XBYCANI67DYUQV5 size 114314 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/UOUASLVAWT2CERC53XBYCANI67DYUQV5\n",
      "get data of  20180726161616 digest W7JCXBHMOG5F4V6I7QOBT76SHHYFAVRX size 114049 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/W7JCXBHMOG5F4V6I7QOBT76SHHYFAVRX\n",
      "get data of  20180802205833 digest 2SQFALQDMZSNJGJBCPLBHUEIPEBES7RH size 114416 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/2SQFALQDMZSNJGJBCPLBHUEIPEBES7RH\n",
      "get data of  20180809213815 digest C5IVVT5GYWHBL4VL3M6VJIMAD2DPPLG6 size 114416 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/C5IVVT5GYWHBL4VL3M6VJIMAD2DPPLG6\n",
      "get data of  20180817024652 digest XTOAB433LDVZCO4JSA63JXU6QAVIMU4A size 114416 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/XTOAB433LDVZCO4JSA63JXU6QAVIMU4A\n",
      "get data of  20180824005543 digest DIPUBCDFPZEKVM4S2BAEYE7QPBC2FBO4 size 114416 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/DIPUBCDFPZEKVM4S2BAEYE7QPBC2FBO4\n",
      "get data of  20180830231238 digest ANLCAOFROJS6XT424VVGKB3O75SFE4QT size 114416 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/ANLCAOFROJS6XT424VVGKB3O75SFE4QT\n",
      "get data of  20180907011455 digest M6FXUMOFDJOGZSA2DOVQUGMCESIKAD2C size 114416 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/M6FXUMOFDJOGZSA2DOVQUGMCESIKAD2C\n",
      "get data of  20180913203256 digest U7FS4IHRUYC5MMS2YKYK7RYLSXOZPX2Z size 114806 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/U7FS4IHRUYC5MMS2YKYK7RYLSXOZPX2Z\n",
      "get data of  20180920183721 digest 6TY6NMZ3MFLR4VQ6INZRWSQDN5VSK3KW size 83515 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/6TY6NMZ3MFLR4VQ6INZRWSQDN5VSK3KW\n",
      "get data of  20180928160919 digest 7WTPGILK7Y6TNAWMVBI6ZE65BP3P2GOG size 83515 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/7WTPGILK7Y6TNAWMVBI6ZE65BP3P2GOG\n",
      "get data of  20181005201045 digest BH6S2AJVFXIA4ZTJOULD7FAKSZNVYTOX size 83845 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/BH6S2AJVFXIA4ZTJOULD7FAKSZNVYTOX\n",
      "get data of  20181011182849 digest 5V24MQETKRTUWQWG3W552J5L4IQFQEQR size 83861 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/5V24MQETKRTUWQWG3W552J5L4IQFQEQR\n",
      "get data of  20181018192437 digest T5MAFOX7XICAWWASHKITUMGHVQ345APN size 83869 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/T5MAFOX7XICAWWASHKITUMGHVQ345APN\n",
      "get data of  20181025183342 digest 4ABQWDHMOEA7UPKY6TDXIYUDHKFEL7BT size 84224 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/4ABQWDHMOEA7UPKY6TDXIYUDHKFEL7BT\n",
      "get data of  20181101211903 digest NFHFFTLMWMBWOTVBQTVDIX5ZHT5TRRFS size 84224 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/NFHFFTLMWMBWOTVBQTVDIX5ZHT5TRRFS\n",
      "get data of  20181109124020 digest A5IH5KMSOACYXM6MOTEVZN46Y7LO67XU size 84224 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/A5IH5KMSOACYXM6MOTEVZN46Y7LO67XU\n",
      "get data of  20181117152209 digest 5LM3VHY4QGFNJH5QAKBCCNNU2P2IRHYK size 84527 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/5LM3VHY4QGFNJH5QAKBCCNNU2P2IRHYK\n",
      "get data of  20181122141449 digest AGK2OTNSJEGBXWNVQUTNKDEQKTFVOVYW size 84702 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/AGK2OTNSJEGBXWNVQUTNKDEQKTFVOVYW\n",
      "get data of  20181125154305 digest 3I42H3S6NNFQ2MSVX7XZKYAYSCX5QBYJ size 105124 duplicate True\n",
      "get data of  20181129195626 digest I5MCVBZCU7YFFS6JR7TZ6NMBRBOLUZ6S size 84962 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/I5MCVBZCU7YFFS6JR7TZ6NMBRBOLUZ6S\n",
      "get data of  20181206201347 digest J65HBN75JBNALDJLZGQI6KIFVAQZ5545 size 84962 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/J65HBN75JBNALDJLZGQI6KIFVAQZ5545\n",
      "get data of  20181220120043 digest Q43NI4RAEXLM7UZAM27MRYCXFQWIN6UH size 85249 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/Q43NI4RAEXLM7UZAM27MRYCXFQWIN6UH\n",
      "get data of  20181229010428 digest WUAFJGAQZ4X5TBSPQWIE5TP7L6TZIX6I size 85249 duplicate False\n",
      "created file /var/datasets/ia/wbm/captures/WUAFJGAQZ4X5TBSPQWIE5TP7L6TZIX6I\n",
      "already have /var/datasets/ia/wbm/urls/a5d099af8ea22a17edc3bc46b6535aeb/2018\n",
      "we got all\n"
     ]
    }
   ],
   "source": [
    "store_captures_to_dataset('https://reactjs.org/blog/all.html', 2019)\n",
    "store_captures_to_dataset('https://reactjs.org/blog/all.html', 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4384\r\n",
      "drwxr-xr-x 2 root root   4096 Feb 10 10:02 \u001b[0m\u001b[01;34m.\u001b[0m/\r\n",
      "drwxr-xr-x 4 root root   4096 Feb 10 09:54 \u001b[01;34m..\u001b[0m/\r\n",
      "-rw-r--r-- 1 root root 114494 Feb 10 10:02 2SQFALQDMZSNJGJBCPLBHUEIPEBES7RH\r\n",
      "-rw-r--r-- 1 root root 105202 Feb 10 10:01 3I42H3S6NNFQ2MSVX7XZKYAYSCX5QBYJ\r\n",
      "-rw-r--r-- 1 root root 112981 Feb 10 10:02 3VH4KC64AQSSUU64BSM6KNPYGPZEGL6Y\r\n",
      "-rw-r--r-- 1 root root  84304 Feb 10 10:02 4ABQWDHMOEA7UPKY6TDXIYUDHKFEL7BT\r\n",
      "-rw-r--r-- 1 root root 112013 Feb 10 10:02 4Y3HB5PIWL4B7NJXQRSD4QXZT7QA56GQ\r\n",
      "-rw-r--r-- 1 root root  84607 Feb 10 10:02 5LM3VHY4QGFNJH5QAKBCCNNU2P2IRHYK\r\n",
      "-rw-r--r-- 1 root root  83940 Feb 10 10:02 5V24MQETKRTUWQWG3W552J5L4IQFQEQR\r\n",
      "-rw-r--r-- 1 root root 113443 Feb 10 10:02 6G6ALNC7PFZARXDRZLSPRQPPRNDHCUXW\r\n",
      "-rw-r--r-- 1 root root  83593 Feb 10 10:02 6TY6NMZ3MFLR4VQ6INZRWSQDN5VSK3KW\r\n",
      "-rw-r--r-- 1 root root 112981 Feb 10 10:02 6ZMC7XC62LV3A7NP3GLUJ3YW3VTNLZFE\r\n",
      "-rw-r--r-- 1 root root  83593 Feb 10 10:02 7WTPGILK7Y6TNAWMVBI6ZE65BP3P2GOG\r\n",
      "-rw-r--r-- 1 root root  84304 Feb 10 10:02 A5IH5KMSOACYXM6MOTEVZN46Y7LO67XU\r\n",
      "-rw-r--r-- 1 root root  84782 Feb 10 10:02 AGK2OTNSJEGBXWNVQUTNKDEQKTFVOVYW\r\n",
      "-rw-r--r-- 1 root root 114494 Feb 10 10:02 ANLCAOFROJS6XT424VVGKB3O75SFE4QT\r\n",
      "-rw-r--r-- 1 root root  83924 Feb 10 10:02 BH6S2AJVFXIA4ZTJOULD7FAKSZNVYTOX\r\n",
      "-rw-r--r-- 1 root root 114494 Feb 10 10:02 C5IVVT5GYWHBL4VL3M6VJIMAD2DPPLG6\r\n",
      "-rw-r--r-- 1 root root  85325 Feb 10 09:56 DEF74AUAWCAIQBSM727UVAYKEDNWH4O5\r\n",
      "-rw-r--r-- 1 root root 114494 Feb 10 10:02 DIPUBCDFPZEKVM4S2BAEYE7QPBC2FBO4\r\n",
      "-rw-r--r-- 1 root root 112981 Feb 10 10:02 DRT22WB2QX4NUOCJQMG7MW6472MGUK3T\r\n",
      "-rw-r--r-- 1 root root 114392 Feb 10 10:02 EX5JXMPE6NWTW3NGGU2JBSBXNHFHDGWS\r\n",
      "-rw-r--r-- 1 root root 112909 Feb 10 10:02 GZAGLNDBVVZ2CJGP3JCL5TX6MIYEDM6L\r\n",
      "-rw-r--r-- 1 root root  85042 Feb 10 10:02 I5MCVBZCU7YFFS6JR7TZ6NMBRBOLUZ6S\r\n",
      "-rw-r--r-- 1 root root  85042 Feb 10 10:02 J65HBN75JBNALDJLZGQI6KIFVAQZ5545\r\n",
      "-rw-r--r-- 1 root root 113443 Feb 10 10:02 JHWK6PF3JYBOIN7BLG4XVMIZB44ISFW2\r\n",
      "-rw-r--r-- 1 root root 113860 Feb 10 10:02 KHZJLS2GAE4XDAXJ4TBHNBHQQ54DMNTA\r\n",
      "-rw-r--r-- 1 root root 112013 Feb 10 10:02 KZ46UQTOHTN2OD7O3RPTSXCSXLSOM4NV\r\n",
      "-rw-r--r-- 1 root root  85329 Feb 10 09:56 L5BSSVD5RZJSH7ROECXBDWITK4UFWUXG\r\n",
      "-rw-r--r-- 1 root root  85329 Feb 10 09:56 LK6UWHFG4DBLQCNF4MW3RS7ECJIJ6O5Q\r\n",
      "-rw-r--r-- 1 root root 105202 Feb 10 10:02 LQVFP25IB2LSUFCFC4CDN5G3UQO4IRPM\r\n",
      "-rw-r--r-- 1 root root 114494 Feb 10 10:02 M6FXUMOFDJOGZSA2DOVQUGMCESIKAD2C\r\n",
      "-rw-r--r-- 1 root root  84304 Feb 10 10:02 NFHFFTLMWMBWOTVBQTVDIX5ZHT5TRRFS\r\n",
      "-rw-r--r-- 1 root root 112981 Feb 10 10:02 NTQ2WGTCLDJQWX3KCB7EHPYKYBE3VNPW\r\n",
      "-rw-r--r-- 1 root root 112981 Feb 10 10:02 NYKLGBOVH3TGPUXSJ7CK22QPRSPL5TWD\r\n",
      "-rw-r--r-- 1 root root  85329 Feb 10 10:02 Q43NI4RAEXLM7UZAM27MRYCXFQWIN6UH\r\n",
      "-rw-r--r-- 1 root root  83948 Feb 10 10:02 T5MAFOX7XICAWWASHKITUMGHVQ345APN\r\n",
      "-rw-r--r-- 1 root root 114884 Feb 10 10:02 U7FS4IHRUYC5MMS2YKYK7RYLSXOZPX2Z\r\n",
      "-rw-r--r-- 1 root root 114392 Feb 10 10:02 UOUASLVAWT2CERC53XBYCANI67DYUQV5\r\n",
      "-rw-r--r-- 1 root root  85591 Feb 10 09:56 UYEWLPMCLR6CGWMH5IIYW2BSEUD4FI6D\r\n",
      "-rw-r--r-- 1 root root 114127 Feb 10 10:02 W7JCXBHMOG5F4V6I7QOBT76SHHYFAVRX\r\n",
      "-rw-r--r-- 1 root root 105579 Feb 10 10:02 WSENYGTQRXJ5LNFGHSNQUWH4PB5GEIL2\r\n",
      "-rw-r--r-- 1 root root  85329 Feb 10 10:02 WUAFJGAQZ4X5TBSPQWIE5TP7L6TZIX6I\r\n",
      "-rw-r--r-- 1 root root 114494 Feb 10 10:02 XTOAB433LDVZCO4JSA63JXU6QAVIMU4A\r\n",
      "-rw-r--r-- 1 root root 112013 Feb 10 10:02 YPCA7YY2PVF6SWZJY5INY4RSHGXVUMW3\r\n",
      "-rw-r--r-- 1 root root  85329 Feb 10 09:56 ZA7BK666OTUPAXGSCOU3WT6CXXMCIUV4\r\n"
     ]
    }
   ],
   "source": [
    "%ls -la /var/datasets/ia/wbm/captures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
